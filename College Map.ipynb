{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-api-python-client in /anaconda3/lib/python3.7/site-packages (1.7.8)\n",
      "Requirement already up-to-date: google-auth-httplib2 in /anaconda3/lib/python3.7/site-packages (0.0.3)\n",
      "Requirement already up-to-date: google-auth-oauthlib in /anaconda3/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /anaconda3/lib/python3.7/site-packages (from google-api-python-client) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /anaconda3/lib/python3.7/site-packages (from google-api-python-client) (0.12.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /anaconda3/lib/python3.7/site-packages (from google-api-python-client) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /anaconda3/lib/python3.7/site-packages (from google-api-python-client) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /anaconda3/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /anaconda3/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.1 in /anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client) (0.4.5)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "#installing/importing dependencies\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "!pip install gmaps\n",
    "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "\n",
    "import gmaps\n",
    "import pickle\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from urllib.parse import urlencode\n",
    "from ipywidgets import IntProgress\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import display\n",
    "from urllib.request import HTTPError\n",
    "from urllib.request import urlretrieve\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "gmaps.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in credentials\n",
    "with open('apikey.txt') as f:\n",
    "    api_key = f.readline()\n",
    "    f.close\n",
    "\n",
    "with open('ID1.txt') as f:\n",
    "    ID1 = f.readline()\n",
    "    f.close\n",
    "    \n",
    "with open('ID2.txt') as f:\n",
    "    ID2 = f.readline()\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "\n",
    "name1 = 'Sheet1!A2:A'\n",
    "\n",
    "def sheet_to_list(ID, name):\n",
    "    creds = None\n",
    "    # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server()\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "    # Call the Sheets API\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=ID,\n",
    "                                range=name).execute()\n",
    "    values = result.get('values', [])\n",
    "\n",
    "    colleges = [loc[0] for loc in values if len(loc) != 0]\n",
    "    return colleges\n",
    "\n",
    "colleges1 = sheet_to_list(ID1, name1)\n",
    "ranks1 = sheet_to_list(ID1, 'Sheet1!C2:C')\n",
    "colleges2 = sheet_to_list(ID2, 'Sheet1!A2:A')\n",
    "locs2 = sheet_to_list(ID2, 'Sheet1!B2:B')\n",
    "applies = sheet_to_list(ID1, 'Sheet1!D2:D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'Colleges':colleges1, 'applies':applies, 'ranks':ranks1})\n",
    "filtered = frame[frame['applies'] == 'TRUE']\n",
    "filtered_colleges = filtered['Colleges'].values\n",
    "filtered_ranks = filtered['ranks'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_data = pd.read_csv('uscitiesv1.4.csv') #instead of doing this, query google!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_wikipedia(college):\n",
    "    '''Determines which city a college is in based on its Wikipedia entry.\n",
    "    Not the most rigorous, but it works (largely)!'''\n",
    "    try: \n",
    "        query = f'''https://en.wikipedia.org/wiki/{college}'''\n",
    "        urlpath = urlopen(query)\n",
    "    except HTTPError:\n",
    "        college = college.replace(\" \", \"_\")\n",
    "        query =f'''https://en.wikipedia.org/wiki/{college}'''\n",
    "        urlpath = urlopen(query)\n",
    "    string = urlpath.read().decode('utf-8')\n",
    "    city_index = string.split('>').index('Location</th') + 4\n",
    "    if ', ' not in string.split('>')[city_index]:\n",
    "        city = string.split('>')[city_index][:-3]\n",
    "        state_index = string.split('>').index('Location</th') + 8\n",
    "        state = string.split('>')[state_index][:-3]\n",
    "    else:\n",
    "        both = string.split('>')[city_index].split(', ')\n",
    "        city = both[0]\n",
    "        state = both[1][:-3]\n",
    "    try:\n",
    "        abbrev = state_to_abbrev(state)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            state_index = string.split('>').index('Location</th') + 8\n",
    "            state = string.split('>')[state_index][:-3]\n",
    "            abbrev = state_to_abbrev(state)\n",
    "        except ValueError:\n",
    "            state_index = string.split('>').index('Location</th') + 7\n",
    "            state = string.split('>')[state_index][:-5]\n",
    "            abbrev = state_to_abbrev(state)\n",
    "    return city, abbrev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now query wikipedia for the state abbreviations.\n",
    "def state_to_abbrev(state, verbose=False):\n",
    "    '''Checks against the Wikipedia page for U.S. state abbreviations.'''\n",
    "    query = 'https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations'\n",
    "    urlpath = urlopen(query)\n",
    "    string = urlpath.read().decode('utf-8')\n",
    "    abbrev_index = string.split('>').index(state + '</a') + 12\n",
    "    abbrev = string.split('>')[abbrev_index][:-6]\n",
    "    return abbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coords(colleges=None, cities_list=None, states_list=None, ranks_list=None):\n",
    "    '''Takes in list of colleges. Returns DataFrame with city, state, \n",
    "    latitude, longitude, and rank of college.'''\n",
    "    lat, lng = [], []\n",
    "    cities, states = [], []\n",
    "    ranks = []\n",
    "    if type(colleges) == list:\n",
    "        iterations = len(colleges)\n",
    "    else:\n",
    "        iterations = len(cities_list)\n",
    "    f = IntProgress(min=0, max=iterations) # instantiate the progress bar\n",
    "    display(f) # display the progress bar\n",
    "    for i in range(iterations):\n",
    "        f.value += 1\n",
    "        if not cities_list:\n",
    "            try:\n",
    "                city, state = query_wikipedia(colleges[i])\n",
    "            except IndexError:\n",
    "                print('Need to at least input a list of colleges!')\n",
    "        else:\n",
    "            city, state = cities_list[i], states_list[i]\n",
    "            if len(state) > 2:\n",
    "                state = state_to_abbrev(state)\n",
    "        corr_city = cities_data['city']==city #check the city from Wikipedia against the data.\n",
    "        corr_state = cities_data['state_id']==state\n",
    "        corr_df = cities_data[corr_city & corr_state]\n",
    "        try:\n",
    "            lat += [corr_df['lat'].values[0]]\n",
    "            lng += [corr_df['lng'].values[0]]\n",
    "            cities += [city]\n",
    "            states += [state]\n",
    "            if type(ranks) == list:\n",
    "                ranks += [ranks_list[i]]\n",
    "        except IndexError:\n",
    "            print(f\"Can't determine where where {city} is!\")\n",
    "    coords_frame = pd.DataFrame({'City':cities, 'State':states, 'Latitude':lat, \n",
    "                                 'Longitude':lng, 'Ranks':ranks})\n",
    "    return coords_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2685c2b9f9d34564a257ecf871128e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cities2 = [string.split(', ')[0] for string in locs2]\n",
    "states2 = [string.split(', ')[1] for string in locs2]\n",
    "frame2 = find_coords(cities_list=cities2, states_list=states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0461606a6eff49c9b7f114d0724638e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't determine where where University Park is!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb97737f34cc485e9f4dc8e765b40c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make the ranking optional\n",
    "frame1 = find_coords(colleges=list(filtered_colleges), ranks_list=list(filtered_ranks))\n",
    "\n",
    "top_ranked_1 = frame1[frame1['Ranks'] == '1']\n",
    "mid_ranked_1 = frame1[frame1['Ranks'] == '2']\n",
    "low_ranked_1 = frame1[frame1['Ranks'] == '3']\n",
    "\n",
    "plot_1_cities1 = top_ranked_1[['Latitude', 'Longitude']]\n",
    "plot_1_cities2 = mid_ranked_1[['Latitude', 'Longitude']]\n",
    "plot_1_cities3 = low_ranked_1[['Latitude', 'Longitude']]\n",
    "\n",
    "plot_2_cities = frame2[['Latitude', 'Longitude']]\n",
    "\n",
    "top_rank_1_layer = gmaps.symbol_layer(\n",
    "    plot_1_cities1, fill_color='green', stroke_color='green', scale=4)\n",
    "mid_ranked_1_layer = gmaps.symbol_layer(\n",
    "    plot_1_cities2, fill_color='yellow', stroke_color='yellow', scale=4)\n",
    "low_ranked_1_layer = gmaps.symbol_layer(\n",
    "    plot_1_cities3, fill_color='red', stroke_color='red', scale=4)\n",
    "all_2_layer = gmaps.symbol_layer(\n",
    "    plot_2_cities, fill_color='purple', stroke_color='purple', scale=3)\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(top_rank_1_layer)\n",
    "fig.add_layer(mid_ranked_1_layer)\n",
    "fig.add_layer(low_ranked_1_layer)\n",
    "fig.add_layer(all_2_layer)\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
